Often definitions are seen as bad. Richard Fenyman gives a particularly good quote that attacks this. Though he goes on to say the key thing is about communication of ideas.

But this isn't entirely fair - words are actually really important. Understandign definitions well, is a base not just to communicate but also to understand concepts itself. 

For example, if you understand what imperative means, you can grasp well what imperative coding is. The roots of the terms we use are often opaque and hidden, and so become confusing. 

e.g. expression vs arguement vs function vs method. What do all these mean? Can I use the word method in place of function?

Textbooks, guides often introduce these words either accepting the reader knows them already, or thinking that listing a load of definitions at the start will not be helpful. 

But the words are tools for thinking with, they are crutches. If we don't know what they mean, how do we understand the concepts with which they are built on top of?

Which is why, often a good course if it has a few key terms in a lesson should define and explain them. Maybe at the start. Lots of teachers do this in schools - in mathematics a -level for example, or maths mastery. There's a real push to use language carefully. 

Because the truth is as a coder, experienced, you can get away with this being implicit knowledge. You don't need to know exactly what it means, because to some extent others around you who are experienced do have that implicit understanding too. 

But when you're teaching a beginner, they don't have that. They don't have things in their minds that they can link to an arguement or an expression. They can't make a good quick guesstimate. The word in fact will impair learning - as it adds cognitive load. Now the student has to try and deciper what it means, through the context of what you're saying. 

The amount of key words coders use in a daily basis, which we probably couldn't define or explain well is abundant. Why?
